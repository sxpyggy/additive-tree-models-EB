# Simulated data
```{r}
rm(list = ls())
source("./2_zip_bst.R")
draw_figure<-F
# simulated data
seed=1
n<-10000
dat<-zip_sim(n,seed)
names(dat)
hist(dat$pi0)
plot(dat$pi0,dat$lambda)
dat_test<-dat[dat$ind==5,]
aggregate(dat$y,by=list(dat$ind),sum)
aggregate(dat$y,by=list(dat$ind),length)
dat_learn<-dat[dat$ind<5,]
# estimated prob of zeros from poisson
exp(-mean(dat_learn$y))
## empirical proportion of zeros 
(zero_true<-sum(dat_test$y==0)/length(dat_test$y))
# true loss
(loss_true<-mean(neg_ll(dat_test$y, dat_test$pi0, dat_test$lambda)))
# poisson loss
(loss0_true<-mean(neg_ll(dat_test$y, rep(0,nrow(dat_test)), (1-dat_test$pi0)*dat_test$lambda)))
dat_test$bst_T<-(1-dat_test$pi0)*dat_test$lambda
(loss0_True<-mean(neg_ll(dat_test$y,rep(0,nrow(dat_test)),dat_test$bst_T)))
# histogram of N
if (draw_figure==T) png("./plots/2-hist_poisson.png")
hist(dat$y,freq = F, main="",xlab="N", ylab="frequency")
box()
if (draw_figure==T)  dev.off()
```

# Boosting
```{r}
valid_rows<-which(dat_learn$ind==4)
pi00<-sum(dat_learn$y==0)/nrow(dat_learn)
pi0<-rep(pi00, nrow(dat_learn))
lambda00<-mean(dat_learn$y)
lambda0<-rep(lambda00, nrow(dat_learn))
M0<-200
n_tree_lambda<-1
maxdepth_lambda<-2
eta_lambda<-0.3
n_tree_pi<-1
maxdepth_pi<-2
eta_pi<-0.3
trace<-TRUE
patience<-5
```

## BST
```{r}
structure<-"both"
bst_both<-EB_zip(dat_learn, valid_rows, lambda0, pi0, M0,
                          n_tree_lambda, maxdepth_lambda, eta_lambda,
                          n_tree_pi, maxdepth_pi, eta_pi,
                          structure, trace, patience)
matplot(cbind(bst_both$train_loss,bst_both$valid_loss),lty=c(1,1),col=c("red","blue"),type="l")

# bst_both
dat_test$lambda_bst<-rep(lambda00, nrow(dat_test))
dat_test$pi_bst<-rep(pi00, nrow(dat_test))
for (m in 1:which.min(bst_both$valid_loss)){
  dtest_lambda<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]), base_margin=log(dat_test$lambda_bst))
  dtest_pi<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]), base_margin=p_linear(dat_test$pi_bst))
  dat_test$lambda_bst<-predict(bst_both$lambda_models[[m]],newdata=dtest_lambda)
  dat_test$pi_bst<-predict(bst_both$pi_models[[m]],newdata=dtest_pi)
}
## test loss
(loss_bst_both<-mean(neg_ll(dat_test$y,dat_test$pi_bst,dat_test$lambda_bst)))
## mse
(ebst_both_eta<-mean((dat_test$eta-log(dat_test$lambda_bst))^2))
(ebst_both_pif<-mean((dat_test$pi_f-p_linear(dat_test$pi_bst))^2))
plot(dat_test$eta,log(dat_test$lambda_bst))
plot(dat_test$pi_f,p_linear(dat_test$pi_bst))
## estimated proportion of zeros
(zero_bst_both<-mean(dat_test$pi_bst+(1-(dat_test$pi_bst))*exp(-(dat_test$lambda_bst))))
## poisson loss
dat_test$pi_bst0<-0
dat_test$lambda_bst0<-(1-dat_test$pi_bst)*dat_test$lambda_bst
(loss0_bst_both<-mean(neg_ll(dat_test$y,dat_test$pi_bst0,dat_test$lambda_bst0)))
```

## BST-lambda, BST-lambda-pi
```{r}
structure<-"lambda"
bst_lambda<-
  EB_zip(dat_learn, valid_rows, lambda0, pi0, M0, 
         n_tree_lambda, maxdepth_lambda, eta_lambda,
         n_tree_pi, maxdepth_pi, eta_pi,
         structure, trace, patience)
matplot(cbind(bst_lambda$train_loss,bst_lambda$valid_loss),lty=c(1,1),col=c("red","blue"),type="l")
structure<-"pi"
bst_lambda_pi<-
  EB_zip(dat_learn, valid_rows, bst_lambda$lambda_hat, bst_lambda$pi_hat, M0,
         n_tree_lambda, maxdepth_lambda, eta_lambda,
         n_tree_pi, maxdepth_pi, eta_pi,
         structure, trace, patience)
matplot(cbind(bst_lambda_pi$train_loss,bst_lambda_pi$valid_loss),lty=c(1,1),col=c("red","blue"),type="l")

# bst_lambda
dat_test$lambda_bst<-rep(lambda00, nrow(dat_test))
dat_test$pi_bst<-rep(pi00, nrow(dat_test))
for (m in 1:which.min(bst_lambda$valid_loss)){
  dtest_lambda<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]), base_margin=log(dat_test$lambda_bst))
  dtest_pi<-xgb.DMatrix(data=as.matrix(rep(1,nrow(dat_test))), base_margin=p_linear(dat_test$pi_bst))
  dat_test$lambda_bst<-predict(bst_lambda$lambda_models[[m]],newdata=dtest_lambda)
  dat_test$pi_bst<-predict(bst_lambda$pi_models[[m]],newdata=dtest_pi)
}
## test loss
(loss_bst_lambda<-mean(neg_ll(dat_test$y,dat_test$pi_bst,dat_test$lambda_bst)))
## mse
(ebst_lambda_eta<-mean((dat_test$eta-log(dat_test$lambda_bst))^2))
(ebst_lambda_pif<-mean((dat_test$pi_f-p_linear(dat_test$pi_bst))^2))
plot(dat_test$eta,log(dat_test$lambda_bst))
plot(dat_test$pi_f,p_linear(dat_test$pi_bst))
## estimated proportion of zeros
(zero_bst_lambda<-mean(dat_test$pi_bst+(1-(dat_test$pi_bst))*exp(-(dat_test$lambda_bst))))
## poisson loss
dat_test$pi_bst0<-0
dat_test$lambda_bst0<-(1-dat_test$pi_bst)*dat_test$lambda_bst
(loss0_bst_lambda<-mean(neg_ll(dat_test$y,dat_test$pi_bst0,dat_test$lambda_bst0)))

# bst_lambda_pi
for (m in 1:which.min(bst_lambda_pi$valid_loss)){
  dtest_lambda<-xgb.DMatrix(data=as.matrix(rep(1,nrow(dat_test))), base_margin=log(dat_test$lambda_bst))
  dtest_pi<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]), base_margin=p_linear(dat_test$pi_bst))
  dat_test$lambda_bst<-predict(bst_lambda_pi$lambda_models[[m]],newdata=dtest_lambda)
  dat_test$pi_bst<-predict(bst_lambda_pi$pi_models[[m]],newdata=dtest_pi)
}
## test loss
(loss_bst_lambda_pi<-mean(neg_ll(dat_test$y,dat_test$pi_bst,dat_test$lambda_bst)))
```

### Variable relative importance
```{r}
vi_lambda<-data.frame(matrix(0,nrow=length(bst_lambda$valid_loss),ncol=5))
X_ind<-data.frame(X=c("x1","x2","x3","x4","x5"),ind=1:5)
for (m in 1:length(bst_lambda$valid_loss)){
  boost_model<-bst_lambda$lambda_models[[m]]
  tree_bst<- tryCatch(xgb.model.dt.tree(model = boost_model), error = function(e) NULL)
  if (is.null(tree_bst)==F){
    gain_mat<-aggregate(Quality ~ Feature, data=tree_bst, FUN=sum)
    gain_mat<-gain_mat[-which(gain_mat$Feature=="Leaf"),]
    gain_mat<-merge(X_ind,gain_mat,by.x="X",by.y="Feature",all.x=T)
    gain_mat$Quality[is.na(gain_mat$Quality)]<-0
    vi_lambda[m,]<-gain_mat$Quality[order(gain_mat$ind)]
  }
}

vi<-round(apply(vi_lambda,2,sum)/sum(apply(vi_lambda,2,sum))*100,2)
# write.csv(vi,"./plots/2-zip-imp.csv")
```

## BST-pi, BST-pi-lambda
```{r}
structure<-"pi"
bst_pi<-
  EB_zip(dat_learn, valid_rows, lambda0, pi0, M0,
         n_tree_lambda, maxdepth_lambda, eta_lambda,
         n_tree_pi, maxdepth_pi, eta_pi,
         structure, trace, patience)
matplot(cbind(bst_pi$train_loss,bst_pi$valid_loss),lty=c(1,1),col=c("red","blue"),type="l")
structure<-"lambda"
bst_pi_lambda<-
  EB_zip(dat_learn, valid_rows, bst_pi$lambda_hat, bst_pi$pi_hat, M0,
         n_tree_lambda, maxdepth_lambda, eta_lambda,
         n_tree_pi, maxdepth_pi, eta_pi,
         structure, trace, patience)
matplot(cbind(bst_pi_lambda$train_loss,bst_pi_lambda$valid_loss),lty=c(1,1),col=c("red","blue"),type="l")

# bst_pi
dat_test$lambda_bst<-rep(lambda00, nrow(dat_test))
dat_test$pi_bst<-rep(pi00, nrow(dat_test))
for (m in 1:which.min(bst_pi$valid_loss)){
  dtest_lambda<-xgb.DMatrix(data=as.matrix(rep(1,nrow(dat_test))), base_margin=log(dat_test$lambda_bst))
  dtest_pi<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]), base_margin=p_linear(dat_test$pi_bst))
  dat_test$lambda_bst<-predict(bst_pi$lambda_models[[m]],newdata=dtest_lambda)
  dat_test$pi_bst<-predict(bst_pi$pi_models[[m]],newdata=dtest_pi)
}
## test loss
(loss_bst_pi<-mean(neg_ll(dat_test$y,dat_test$pi_bst,dat_test$lambda_bst)))

# bst_pi_lambda
for (m in 1:which.min(bst_pi_lambda$valid_loss)){
  dtest_lambda<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]), base_margin=log(dat_test$lambda_bst))
  dtest_pi<-xgb.DMatrix(data=as.matrix(rep(1,nrow(dat_test))), base_margin=p_linear(dat_test$pi_bst))
  dat_test$lambda_bst<-predict(bst_pi_lambda$lambda_models[[m]],newdata=dtest_lambda)
  dat_test$pi_bst<-predict(bst_pi_lambda$pi_models[[m]],newdata=dtest_pi)
}
## test loss
(loss_bst_pi_lambda<-mean(neg_ll(dat_test$y,dat_test$pi_bst,dat_test$lambda_bst)))

# test loss comparison
test_loss_comparison<-round(c(loss_bst_both,loss_bst_lambda,loss_bst_lambda_pi,loss_bst_pi,loss_bst_pi_lambda),4)
# write.csv(test_loss_comparison, "./plots/2-zip-bst-loss.csv")
```

# GLM
## NULL
### on the original data
```{r}
null_mle<-mle_zip(dat_learn$y,iter = 30)
plot(null_mle$loss,type="l")
# learn loss
min(null_mle$loss)
# test loss
dat_test$pi_null<-null_mle$pi_hat
dat_test$lambda_null<-null_mle$lambda_hat
mean(dat$pi0);null_mle$pi_hat
mean(dat$lambda);null_mle$lambda_hat
(loss_null<-mean(neg_ll(dat_test$y,dat_test$pi_null,dat_test$lambda_null)))
# mse
(eglm_null_eta<-mean((dat_test$eta-log(dat_test$lambda_null))^2))
(eglm_null_pif<-mean((dat_test$pi_f-p_linear(dat_test$pi_null))^2))
# estimated proportion of zeros
(zero_glm_null<-sum(dat_test$pi_null+(1-dat_test$pi_null)*exp(-dat_test$lambda_null))/length(dat_test$y))

# null poisson model
dat_test$pi_null0<-0
dat_test$lambda_null0<-(1-dat_test$pi_null)*dat_test$lambda_null
(loss0_null<-mean(neg_ll(dat_test$y,dat_test$pi_null0,dat_test$lambda_null0)))
```

### on the augmented data
```{r}
names(dat_learn)
M0<-15
structure="null"
glm_null<-EM_zip(dat_learn,M0,structure)
plot(glm_null$learn_loss,type="l")
min(glm_null$learn_loss)
min(null_mle$loss)
# test loss
dat_test$pi_null2<-predict(glm_null$glm_ber,newdata = dat_test,type="response")
dat_test$lambda_null2<-predict(glm_null$glm_poi,newdata = dat_test,type="response")
(loss_null2<-mean(neg_ll(dat_test$y,dat_test$pi_null2,dat_test$lambda_null2)))
loss_null
# mse
(eglm_null_eta2<-mean((dat_test$eta-log(dat_test$lambda_null2))^2))
eglm_null_eta
(eglm_null_pif2<-mean((dat_test$pi_f-p_linear(dat_test$pi_null2))^2))
eglm_null_pif
```

## GLM
```{r}
M0<-20
structure="both"
glm_both<-EM_zip(dat_learn,M0,structure)
# learn loss
plot(glm_both$learn_loss,type="l")
# test loss
dat_test$lambda_glm_both<-predict(glm_both$glm_poi,newdata = dat_test,type = "response")
dat_test$pi_glm_both<-predict(glm_both$glm_ber,newdata = dat_test,type ="response")
(loss_glm_both<-mean(neg_ll(dat_test$y,dat_test$pi_glm_both,dat_test$lambda_glm_both)))
loss_true
loss_null
# mse
(eglm_both_eta<-mean((dat_test$eta-log(dat_test$lambda_glm_both))^2))
(eglm_both_pif<-mean((dat_test$pi_f-p_linear(dat_test$pi_glm_both))^2))
plot(dat_test$eta,log(dat_test$lambda_glm_both))
plot(dat_test$pi_f,p_linear(dat_test$pi_glm_both))
# estimated proportion of zeros
exp(-mean(dat_test$y))
sum(dat_test$y==0)/length(dat_test$y)
(zero_glm_both<-mean(dat_test$pi_glm_both+(1-(dat_test$pi_glm_both))*exp(-(dat_test$lambda_glm_both))))
# poisson loss
dat_test$pi_glm0<-0
dat_test$lambda_glm0<-(1-dat_test$pi_glm_both)*dat_test$lambda_glm_both
(loss0_glm_both<-mean(neg_ll(dat_test$y,dat_test$pi_glm0,dat_test$lambda_glm0)))
```

## GLM-lambda
```{r}
M0<-20
structure="lambda"
glm_lambda<-EM_zip(dat_learn,M0,structure)
# learn loss
plot(glm_lambda$learn_loss,type="l")
# test loss
dat_test$lambda_glm_lambda<-predict(glm_lambda$glm_poi,newdata = dat_test,type = "response")
dat_test$pi_glm_lambda<-predict(glm_lambda$glm_ber,newdata = dat_test,type ="response")
(loss_glm_lambda<-mean(neg_ll(dat_test$y,dat_test$pi_glm_lambda,dat_test$lambda_glm_lambda)))
loss_true
loss_null
# mse
(eglm_lambda_eta<-mean((dat_test$eta-log(dat_test$lambda_glm_lambda))^2))
(eglm_lambda_pif<-mean((dat_test$pi_f-p_linear(dat_test$pi_glm_lambda))^2))
plot(dat_test$eta,log(dat_test$lambda_glm_lambda))
plot(dat_test$pi_f,p_linear(dat_test$pi_glm_lambda))
# estimated proportion of zeros
(zero_glm_lambda<-mean(dat_test$pi_glm_lambda+(1-(dat_test$pi_glm_lambda))*exp(-(dat_test$lambda_glm_lambda))))
# poisson loss
dat_test$pi_glm0<-0
dat_test$lambda_glm0<-(1-dat_test$pi_glm_lambda)*dat_test$lambda_glm_lambda
(loss0_glm_lambda<-mean(neg_ll(dat_test$y,dat_test$pi_glm0,dat_test$lambda_glm0)))
loss0_null
```

## GLM-pi
```{r}
M0<-20
structure="pi"
glm_pi<-EM_zip(dat_learn,M0,structure)
# learn loss
plot(glm_pi$learn_loss,type="l")
# test loss
dat_test$lambda_glm_pi<-predict(glm_pi$glm_poi,newdata = dat_test,type = "response")
dat_test$pi_glm_pi<-predict(glm_pi$glm_ber,newdata = dat_test,type ="response")
(loss_glm_pi<-mean(neg_ll(dat_test$y,dat_test$pi_glm_pi,dat_test$lambda_glm_pi)))
loss_true
loss_null
# mse
(eglm_pi_eta<-mean((dat_test$eta-log(dat_test$lambda_glm_pi))^2))
(eglm_pi_pif<-mean((dat_test$pi_f-p_linear(dat_test$pi_glm_pi))^2))
plot(dat_test$eta,log(dat_test$lambda_glm_pi))
plot(dat_test$pi_f,p_linear(dat_test$pi_glm_pi))
# estimated proportion of zeros
(zero_glm_pi<-mean(dat_test$pi_glm_pi+(1-(dat_test$pi_glm_pi))*exp(-(dat_test$lambda_glm_pi))))
# poisson loss
dat_test$pi_glm0<-0
dat_test$lambda_glm0<-(1-dat_test$pi_glm_pi)*dat_test$lambda_glm_pi
(loss0_glm_pi<-mean(neg_ll(dat_test$y,dat_test$pi_glm0,dat_test$lambda_glm0)))
```

# Poisson GBDT
```{r}
param<-list(max_depth=6, eta =0.1, objective="count:poisson")
dtrain<-xgb.DMatrix(data=as.matrix(dat_learn[dat_learn$ind<4,c("x1","x2","x3","x4","x5")]), label = dat_learn$y[dat_learn$ind<4])
dvalid<-xgb.DMatrix(data=as.matrix(dat_learn[dat_learn$ind==4,c("x1","x2","x3","x4","x5")]), label = dat_learn$y[dat_learn$ind==4])
dtest<-xgb.DMatrix(data=as.matrix(dat_test[,c("x1","x2","x3","x4","x5")]))
watchlist=list(train=dtrain,eval=dvalid)
bst_poi <- xgb.train(param, dtrain, nrounds=100, verbose = 1, watchlist, early_stopping_rounds = 5)
dat_test$lambda_boost0 <- predict(bst_poi,type="response", newdata = dtest)
dat_test$pi_bst<-0
(loss0_BST0<-mean(neg_ll(dat_test$y,dat_test$pi_bst,dat_test$lambda_boost0))) # under Poisson loss
(zero_bst_0<-mean(exp(-dat_test$lambda_boost0)))
```

# Model comparison
```{r}
loss_mat<-data.frame(
  model=c("null","glm_lambda","glm_pi","glm_both","bst_lambda","bst_both","GBDT","true"),
  negL=c(loss_null,loss_glm_lambda,loss_glm_pi,loss_glm_both,loss_bst_lambda,loss_bst_both,NA,loss_true),loss0=NA,error_pif=NA,error_eta=NA)
loss_mat$error_pif<-c(eglm_null_pif,eglm_lambda_pif,eglm_pi_pif,eglm_both_pif,ebst_lambda_pif,ebst_both_pif,NA,0)
loss_mat$error_eta<-c(eglm_null_eta,eglm_lambda_eta,eglm_pi_eta,eglm_both_eta,ebst_lambda_eta,ebst_both_eta,NA,0)
loss_mat$loss0<-c(loss0_null,loss0_glm_lambda,loss0_glm_pi,loss0_glm_both,loss0_bst_lambda,loss0_bst_both,loss0_BST0,loss0_True)
loss_mat$proportion_0<-c(zero_glm_null,zero_glm_lambda,zero_glm_pi,zero_glm_both,zero_bst_lambda,zero_bst_both,zero_bst_0,zero_true)
loss_mat[,2:6]<-round(loss_mat[,2:6],4)
loss_mat
(loss_mat<-loss_mat[c(5,2,1,7,8),])
# write.csv(loss_mat,"./plots/2-zip_loss_mat.csv")
```
